{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83e4c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; import numpy as np;\n",
    "import os; import math; import copy\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "#torch\n",
    "import torch; import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "#transformer tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "#load data pre-processing and model\n",
    "%run model.ipynb\n",
    "%run data_preprocessing.ipynb\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57e696d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer\n",
    "checkpoint = \"Salesforce/codegen-350M-mono\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "#add section tokens\n",
    "tokenizer.add_tokens(['<PRE-S>'], special_tokens=False)\n",
    "tokenizer.add_tokens(['<PRE-E>'], special_tokens=False)\n",
    "tokenizer.add_tokens(['<MID-S>'], special_tokens=False)\n",
    "tokenizer.add_tokens(['<MID-E>'], special_tokens=False)\n",
    "tokenizer.add_tokens(['<SUF-S>'], special_tokens=False)\n",
    "tokenizer.add_tokens(['<SUF-E>'], special_tokens=False)\n",
    "tokenizer.add_tokens(['<PAD>'], special_tokens=False)\n",
    "\n",
    "pre_s = tokenizer.encode('<PRE-S>')\n",
    "pre_e = tokenizer.encode('<PRE-E>')\n",
    "mid_s = tokenizer.encode('<MID-S>')\n",
    "mid_e = tokenizer.encode('<MID-E>')\n",
    "suf_s = tokenizer.encode('<SUF-S>')\n",
    "suf_e = tokenizer.encode('<SUF-E>')\n",
    "PAD = tokenizer.encode('<PAD>')\n",
    "\n",
    "#data\n",
    "path = '/Users/kchen/Documents/Machine Learning/Models/Transformer Architecture/CodeLLM/Code/data/the_stack/'\n",
    "text = pd.read_parquet(path+'data-00000-of-00144.parquet') #get python script table\n",
    "text = text[text['size']>1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "535259fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters:\n",
    "num_scripts, batch_size, block_size = 4, 32, 64\n",
    "max_iters, eval_interval, eval_iters = 50000, 500, 500\n",
    "n_embd, n_head, n_layer, dropout = 576, 8, 6, 0.2\n",
    "learning_rate, vocab_size = 6e-4, len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a9fbeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.479326 M parameters\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "#model = CodeLanguageModel().to(device)\n",
    "model = torch.load('./models/model.pt').to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca271977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, max_iters, eval_interval):\n",
    "    for iter in range(max_iters):\n",
    "        #randomly load data\n",
    "        xb, yb = get_batch(text, num_scripts=num_scripts,\n",
    "                                 batch_size=batch_size,\n",
    "                                 block_size=block_size)\n",
    "        # apply model and evaluate loss\n",
    "        logits, loss = model(xb, yb)\n",
    "        #back-prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #given the pre-trained size, train-loss as indicator is sufficient (Adam)\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "            print(f\"step {iter}: train loss {loss.cpu().item():.4f}\")\n",
    "        #clear cache and del variables to save space\n",
    "        torch.cuda.empty_cache()\n",
    "        del xb, yb, logits, loss\n",
    "\n",
    "train(model, max_iters, eval_interval)\n",
    "#torch.save(model, './models/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ce7dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "87e92913",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "<PRE-S> import pandas as pd\n",
      "from geopideim import Dict\n",
      "import ctypes as bids\n",
      "\n",
      "from pdb import tables, DataEntry\n",
      "\n",
      "\n",
      "def json_obj(t_uid, **kwargs):\n",
      "    params = {}\n",
      "    print 'training data properties.{0: sampler.data(datetime.time.time.time())} sect\\n\\n'\n",
      "    for idx, (idx, lidx)] = {\n",
      "        k,\n",
      "        kspace,\n",
      "        abspathem,\n",
      "    for_key, (idx, n) in enumerate(l_ports_list):\n",
      "        for rootk, prefix in enumerateitems():\n",
      "            string = np.append(rootidx.__string(80) * vec_heap['sumen | (MESSA/8) + vec_heap['sumen ;Secs {fs_heap['val'.<MID-E><SUF-S>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "<PRE-S> import pandas as pd\n",
      "import requests\n",
      "\n",
      "with open(\"./table\") as data:\n",
      "    data = json.load(data)\n",
      "CSV_A = json_load.open(\"./table_country_chks/klayout/SUCCESS_API_URI.json\",'r')\n",
      "\n",
      "\n",
      "for userWord in tweets[\"email-Code:domain]\n",
      "\n",
      "# User cookies\n",
      "usernameerConfirm=userBlack['username'][userUserName]\n",
      "authMatch=userToken.get_auth_patterns(authenticate_username_id)\n",
      "authtoken = authToken.get_auth_auth_token(authtoken)\n",
      "authauthtoken = default_auth(testauthtoken, adminToken)\n",
      "authtoken = authtoken.token_scum(logintoken)\n",
      "loginlog = Webhook()\n",
      "logger.info(f\"%s running %s!!\")\n",
      "\n",
      "url = authtoken.url\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "<PRE-S> import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "train_test=0\n",
      "testMNIST_M_CLAN=0\n",
      "test_test=0.6\n",
      "test_Bin=5\n",
      "testP(\"pretreshape1d-file\", apiPouse=2)\n",
      "\n",
      "evalID=pycpu.0\n",
      "testFranMode=0\n",
      "testRt=futility.run(TEST, PASS_NULL=True)\n",
      "print(random.randint(testSPREC_REQUEST_SIZE, MAX_NUMBER), cpu_hidden, \"\")\n",
      "When(testBackend=infoElectance\", bnast=orsxt)\n",
      "\n",
      "\n",
      "def setup():\n",
      "    os.environ[\"CUDA_ROOT\"] = csv.<PRE-E><SUF-S>getOpenTimedRotatedFileFromFile(\"BATTLE/Bird\")\n",
      "\n",
      "    def getFileReference(cluster, target=\"\"\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "<PRE-S> import pandas as pd\n",
      "\n",
      "policy = PCA(\n",
      "    model_name='steies')\n",
      "\n",
      "for f in 401bar<PRE-E><MID-S>:\n",
      "    if e == 0:\n",
      "        e0 = -0\n",
      "        state_dict = {\n",
      "           'secBuilder': args.conv_simple_lines,\n",
      "            'height': args.varpost_height,\n",
      "            'temperature':args.varvalue,\n",
      "            'im': args.varvalue_threshold,\n",
      "           'scale': args.scale,\n",
      "            'taled': args.infrescale,\n",
      "           'mhme': vvalues_threshold,\n",
      "            'temp': args.pandas,\n",
      "            llonymous=True,\n",
      "            'neigr': args.mode,\n",
      "        }\n",
      "        flags[os.getenv(\"JERSText with default\"),\n",
      "        'izls_settings': environvar( diabetes_helpting(settingsxml)))\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "<PRE-S> import pandas as pdb\n",
      "\n",
      "tree = TreeNode(2, TreeNode)\n",
      "print(tree)\n",
      "tree.add(1, TreeNode(3, TreeNode(6, TreeNode(3, TreeNode(8, TreeNode(7, TreeNode(\"0\",1))])\n",
      "tree.add(4, TreeNode(5, TreeNode(5, TreeNode(6)), TreeNode(7, TreeNode(5))\n",
      "tree.add(5)\n",
      "tree.add(5, TreeNode(9, TreeNode(3))\n",
      "tree.add(5, TreeNode(5))\n",
      "\n",
      "tree.add(5, TreeNode(5))\n",
      "tree.add(5, TreeNode(12))\n",
      "tree.add(5, TreeNode([6, TreeNode(20)), TreeNode(20))\n",
      "tree.add(5, TreeNode(25))\n",
      "tree.add(5, TreeNode([7])\n",
      "tree.\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "    context = '<PRE-S> import pandas as' #enter some python script here\n",
    "    context = torch.tensor(tokenizer.encode(context)).unsqueeze(0).to(device)\n",
    "    print(tokenizer.decode(model.generate(context, max_new_tokens=200).cpu().tolist()[0]))\n",
    "    print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad2e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
